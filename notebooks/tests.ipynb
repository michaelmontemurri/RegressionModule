{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss_estimation.py\n",
    "\n",
    "This file provides functions to calculate different types of loss estimators for a given model over a dataset. These include the naive loss, training/testing loss, and leave-one-out loss estimators. The functions can be used with any model that implements the `fit()` and `predict()` methods.\n",
    "\n",
    "##### `naive_loss_estimation(model, X, y)`\n",
    "Calculates the naive loss estimator for a given model over a given dataset.\n",
    "\n",
    "##### Parameters:\n",
    "- **model** (`object`): The model for which the naive loss will be calculated. The model must have `fit()` and `predict()` methods implemented.\n",
    "- **X** (`numpy.ndarray`): A 2D array of shape `(n_samples, n_features)` representing the feature set of the dataset.\n",
    "- **y** (`numpy.ndarray`): A 1D array of length `n_samples` representing the true response values corresponding to the features in `X`.\n",
    "\n",
    "##### Returns:\n",
    "- **naive_loss_estimate** (`float`): The naive loss estimate, calculated as the mean squared error (MSE) between the true and predicted values.\n",
    "\n",
    "\n",
    "\n",
    "##### `train_test_loss_estimation(model, X, y, train_range, test_range)`\n",
    "This function calculates the training/testing loss estimator for a given model over a dataset, using a training set and a test set. The model is trained on the training set and evaluated on the test set. The loss is calculated as the Mean Squared Error (MSE) between the predicted and actual responses on the test set.\n",
    "\n",
    "##### Parameters:\n",
    "- **model** (`object`): The model for which the naive loss will be calculated. The model must have `fit()` and `predict()` methods implemented.\n",
    "- **X** (`numpy.ndarray`): A 2D array of shape `(n_samples, n_features)` representing the feature set of the dataset.\n",
    "- **y** (`numpy.ndarray`): A 1D array of length `n_samples` representing the true response values corresponding to the features in `X`.\n",
    "- **train_range** (`list`): The list of indices which will be used to train the model.\n",
    "- **test_range** (`list`): The list of indices which will the MSE of the trained model will be calculated on.\n",
    "\n",
    "##### Returns:\n",
    "- **train_test_loss_estimate** (`float`): The training-testing loss estimate, calculated as the mean squared error (MSE) between the true and predicted values over the testing data-set using the model trained on the training data set.\n",
    "\n",
    "\n",
    "\n",
    "##### `loss_test_loss_estimation(model, X, y))`\n",
    "Calculates the leave-one-out (LOO) loss estimator for a given model over a given dataset. Assumes that the model is a linear model and utilizes the known closed form solution for the LOO loss estimator for linear models for computational efficiency.\n",
    "\n",
    "##### Parameters:\n",
    "- **model** (`object`): The model for which the naive loss will be calculated. The model must have `fit()` and `predict()` methods implemented.\n",
    "- **X** (`numpy.ndarray`): A 2D array of shape `(n_samples, n_features)` representing the feature set of the dataset.\n",
    "- **y** (`numpy.ndarray`): A 1D array of length `n_samples` representing the true response values corresponding to the features in `X`.\n",
    "\n",
    "##### Returns:\n",
    "- **loo_loss_estimate** (`float`): The leave-one-out loss estimate, calculated using the closed form solution which is known for linear models.\n",
    "\n",
    "\n",
    "### Example\n",
    "Below is a code snippet where the three loss-estimations are used in practice for an OLS-estimator using a generated data set. In the first and second outputs we showcase that when given the entire data set for training and testing, the training-testing loss estimator reduces to the naive loss estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from stats_module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate data:\n",
    "- For $n=1000$ samples and $p = 10$ covariates, generate design matrix X as standard normal data.\n",
    "- Generate $y = X\\beta + e$, where $\\beta$ is given and $e$ is from a standard normal distribution.\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'randn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      3\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandn\u001b[49m(n,p)\n\u001b[1;32m      5\u001b[0m beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m,p\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m e \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandn(n)\n",
      "File \u001b[0;32m~/Documents/FALL2024/MATH533/A4/regression_module/venv/lib/python3.12/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'randn'"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n = 1000\n",
    "p = 10\n",
    "X = np.random.randn(n,p)\n",
    "beta = np.arange(1,p+1)\n",
    "e = np.random.randn(n)\n",
    "y = X @  beta + e\n",
    "\n",
    "model = OLS(include_intercept=True)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Naive:\\t\\t\\t\" +              str(naive_loss_estimation(model,X,y)))\n",
    "print(\"Train-Test (full/full):\\t\" + str(train_test_loss_estimation(model, X, y, list(range(1,1000)), list(range(1,1000)) )))\n",
    "print(\"Train-Test (half/half)):\" +  str(train_test_loss_estimation(model, X, y, list(range(1,500)), list(range(500,1000)) )))\n",
    "print(\"Leave-one-out:\\t\\t\" +        str(loo_loss_estimation(model, X, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinearModelTester.py\n",
    "\n",
    "The file holds a class for performing hypothesis tests and building confidence intervals on a fitted gaussian homoscedastic linear model.\n",
    "\n",
    "### Initialization:\n",
    "#### LinearModelTester(model)\n",
    "##### Parameters:\n",
    "- **model** (`object`): A fitted linear model object with:\n",
    "    - **$\\beta$** (`numpy.ndarray`): Estimated coefficients of the model.\n",
    "    - **include_intercept** (`bool`): Whether the model includes an intercept term.\n",
    "##### Raises:\n",
    "- ValueError: If the model is not fitted (**\\beta** is None).\n",
    "\n",
    "\n",
    "### Methods:\n",
    "#### `hypothesis_t_test(X, y, null_hypothesis, alpha=0.05)`:\n",
    "Perform a t-test for individual coefficients.\n",
    "##### Parameters:\n",
    "- **X** (`numpy.ndarray`): Feature matrix $(n x p)$.\n",
    "- **y** (`numpy.ndarray`): Response vector $(n x 1)$.\n",
    "- **null_hypothesis** (`numpy.ndarray`): Hypothesized values of coefficients.\n",
    "- **$\\alpha$** (`float`): Significance level (default 0.05).\n",
    "##### Returns:\n",
    "- List of dictionaries with:\n",
    "    - **coefficient** (`int`): Index of the coefficient.\n",
    "    - **beta_estimate** (`numpy.ndarray`): Estimated value.\n",
    "    - **null_value** (`float`): Null hypothesis value for the coefficient.\n",
    "    - **t_stat** (`float`): T-statistic.\n",
    "    - **p_value** (`float`): P-value for t-statistic at significance level $\\alpha$.\n",
    "    - **reject_null** (`bool`): Whether the null hypothesis is rejected.\n",
    "\n",
    "#### `hypothesis_F_test(X, y, R, r, alpha=0.05)`:\n",
    "Perform an F-test for hypotheses of the form $R\\beta = r$.\n",
    "##### Parameters:\n",
    "- **X** (`numpy.ndarray`): Feature matrix $(n x p)$.\n",
    "- **y** (`numpy.ndarray`): Response vector $(n x 1)$.\n",
    "- **R** (`numpy.ndarray`): Constraint matrix $(k x p)$.\n",
    "- **r** (`numpy.ndarray`): Constraint vector $(k x 1)$.\n",
    "- **$\\alpha$** (`float`): Significance level (default 0.05).\n",
    "##### Returns:\n",
    "- Dictionary with:\n",
    "    - **F_stat** (`float`): F-statistic.\n",
    "    - **p_value** (`float`): P-value for F-statistic at significance level $\\alpha$.\n",
    "    - **reject_null** (`bool`): Whether the null hypothesis is rejected.\n",
    "\n",
    "#### `confidence_interval(X, y, alpha=0.05)`:\n",
    "Construct confidence intervals for model coefficients.\n",
    "##### Parameters:\n",
    "- **X** (`numpy.ndarray`): Feature matrix $(n x p)$.\n",
    "- **y** (`numpy.ndarray`): Response vector $(n x 1)$.\n",
    "- **$\\alpha$** (`float`): Significance level (default 0.05).\n",
    "##### Returns:\n",
    "- List of dictionaries with:\n",
    "    - **coefficient** (`int`): Index of the coefficient.\n",
    "    - **beta_estimate** (`float`): Estimated value of the coefficient.\n",
    "    - **confidence_lower** (`float`): Lower bound of the $1-\\alpha$ confidence interval.\n",
    "    - **confidence_upper** (`float`): Upper bound of the $1-\\alpha$ confidence interval.\n",
    "\n",
    "#### `prediction_interval_m(X, y, x_new, alpha=0.05)`:\n",
    "Construct a confidence interval for $m(x_{new}) = x_{new}^\\top\\beta$ at a new point ($x_{new}$).\n",
    "##### Parameters:\n",
    "- **X** (`numpy.ndarray`): Feature matrix $(n x p)$.\n",
    "- **y** (`numpy.ndarray`): Response vector $(n x 1)$.\n",
    "- **x_new** (`numpy.ndarray`): New feature vector $(1 x p)$.\n",
    "- **$\\alpha$** (`float`): Significance level (default 0.05).\n",
    "#### Returns:\n",
    "- Dictionary with:\n",
    "    - **mx_new_estimate** (`np.ndarray`): Estimated $m(x_{new})$.\n",
    "    - **confidence_lower** (`float`): Lower bound of the $1-\\alpha$ confidence interval.\n",
    "    - **confidence_upper** (`float`): Upper bound of the $1-\\alpha$ confidence interval.\n",
    "\n",
    "#### `prediction_interval_y(X, y, x_new, alpha=0.05)`:\n",
    "Construct a confidence interval for a new observation, $y_{new}$.\n",
    "##### Parameters:\n",
    "- **X** (`numpy.ndarray`): Feature matrix $(n x p)$.\n",
    "- **y** (`numpy.ndarray`): Response vector $(n x 1)$.\n",
    "- **x_new** (`numpy.ndarray`): New feature vector $(1 x p)$.\n",
    "- **$\\alpha$** (`float`): Significance level (default 0.05).\n",
    "#### Returns\n",
    "- Dictionary with:\n",
    "    - **mx_new_estimate** (`np.ndarray`): Estimated $m(x_{new})$.\n",
    "    - **confidence_lower** (`float`): Lower bound of the $1-\\alpha$ confidence interval for $y_{new}$.\n",
    "    - **confidence_upper** (`float`): Upper bound of the $1-\\alpha$ confidence interval for $y_{new}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coefficients': array([-0.41221599,  0.93623639,  2.38843176,  2.99360915]), 'r_squared': np.float64(0.9786838149519005)}\n"
     ]
    }
   ],
   "source": [
    "#generate a random dataset\n",
    "np.random.seed(0)\n",
    "n = 1000\n",
    "p = 10\n",
    "X = np.randn(n,p)\n",
    "beta = np.arange(1,p+1)\n",
    "e = np.randn(n)\n",
    "y = X @  beta + e\n",
    "\n",
    "#fit an OLS estimator\n",
    "model = OLS(include_intercept=True)\n",
    "model.fit(X, y)\n",
    "\n",
    "#generate new point to predict\n",
    "x_new = np.random.randn(1, p)\n",
    "\n",
    "summary = model.summary(X,y)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient 0:\n",
      "  Estimated: -0.41221598820940447\n",
      "  Null value: 0\n",
      "  t-stat: -2.440361254246725\n",
      "  p-value: 0.026682263977906073\n",
      "  Reject null: True\n",
      "Coefficient 1:\n",
      "  Estimated: 0.9362363940133275\n",
      "  Null value: 1\n",
      "  t-stat: -0.46340266445100076\n",
      "  p-value: 0.6493169758975523\n",
      "  Reject null: False\n",
      "Coefficient 2:\n",
      "  Estimated: 2.388431760388897\n",
      "  Null value: 2\n",
      "  t-stat: 2.4816537047952063\n",
      "  p-value: 0.024563519243711474\n",
      "  Reject null: True\n",
      "Coefficient 3:\n",
      "  Estimated: 2.993609153939517\n",
      "  Null value: 3\n",
      "  t-stat: -0.03907216395463594\n",
      "  p-value: 0.9693162326966738\n",
      "  Reject null: False\n",
      "--------------------------------------------------------------------------------\n",
      "Coefficient 0:\n",
      "  Estimated: -0.41221598820940447\n",
      "  Confidence interval: [-0.7703018479599026, -0.0541301284589063]\n",
      "--------------------------------------------------------------------------------\n",
      "Coefficient 1:\n",
      "  Estimated: 0.9362363940133275\n",
      "  Confidence interval: [0.6445401725668481, 1.2279326154598067]\n",
      "--------------------------------------------------------------------------------\n",
      "Coefficient 2:\n",
      "  Estimated: 2.388431760388897\n",
      "  Confidence interval: [2.056621344760371, 2.7202421760174227]\n",
      "--------------------------------------------------------------------------------\n",
      "Coefficient 3:\n",
      "  Estimated: 2.993609153939517\n",
      "  Confidence interval: [2.6468664333199587, 3.340351874559075]\n",
      "--------------------------------------------------------------------------------\n",
      "F-stat: [[337.97183741]]\n",
      "p-value: [[8.17124146e-14]]\n",
      "Reject null: [[ True]]\n"
     ]
    }
   ],
   "source": [
    "#hypothesis testing on the coefficients\n",
    "\n",
    "tester = LinearModelTester(model)\n",
    "H0 = np.array([0, 1, 2, 3])\n",
    "alpha = 0.05\n",
    "\n",
    "# test H0 for each coefficient\n",
    "\n",
    "results = tester.hypothesis_t_test(X, y, H0, alpha)\n",
    "for result in results:\n",
    "    print(f\"Coefficient {result['coefficient']}:\")\n",
    "    print(f\"  Estimated: {result['beta_estimate']}\")\n",
    "    print(f\"  Null value: {result['null_value']}\")\n",
    "    print(f\"  t-stat: {result['t_stat']}\")\n",
    "    print(f\"  p-value: {result['p_value']}\")\n",
    "    print(f\"  Reject null: {result['reject_null']}\")\n",
    "\n",
    "# build confidence intervals for coefficients\n",
    "results = tester.confidence_interval(X, y, alpha)\n",
    "for result in results:\n",
    "    print('--'*40)\n",
    "    print(f\"Coefficient {result['coefficient']}:\")\n",
    "    print(f\"  Estimated: {result['beta_estimate']}\")\n",
    "    print(f\"  Confidence interval: [{result['confidence_lower']}, {result['confidence_upper']}]\")\n",
    "\n",
    "# hypothesis testing on linear combinations of coefficients\n",
    "R = np.array([\n",
    "    [0, 0, 1, 0],\n",
    "    [0, 1, 0, 1]\n",
    "])\n",
    "r = [0, 0] \n",
    "\n",
    "# H0 = Rbeta = r\n",
    "\n",
    "results = tester.hypothesis_F_test(X, y, R, r, alpha)\n",
    "print('--'*40)\n",
    "print(f\"F-stat: {results['F_stat']}\")\n",
    "print(f\"p-value: {results['p_value']}\")\n",
    "print(f\"Reject null: {results['reject_null']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Prediction interval for new point m[[-1.16514984  0.90082649  0.46566244]]:\n",
      "  Estimated m(x_new): 2.0425022606342313\n",
      "  Confidence interval: [1.4122759816245984, 2.672728539643864]\n",
      "--------------------------------------------------------------------------------\n",
      "Prediction interval for response of new point, y_new:\n",
      "  Confidence interval: [0.44011628066077035, 3.6448882406076923]\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.05\n",
    "result = tester.prediction_interval_m(X, y, x_new, alpha)\n",
    "print('--'*40)\n",
    "print(f\"Prediction interval for new point m{x_new}:\")\n",
    "print(f\"  Estimated m(x_new): {result['mx_new_estimate']}\")\n",
    "print(f\"  Confidence interval: [{result['confidence_lower']}, {result['confidence_upper']}]\")\n",
    "\n",
    "result = tester.prediction_interval_y(X, y, x_new, alpha)\n",
    "print('--'*40)\n",
    "print(f\"Prediction interval for response of new point, y_new:\")\n",
    "print(f\"  Confidence interval: [{result['confidence_lower']}, {result['confidence_upper']}]\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
