{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# models.py Usage\n",
    "\n",
    "This file provides examples and documentation for the key methods implemented in the `OLS`, `GLS`, and `Ridge` regression models. The examples illustrate how to use these methods, including fitting models, making predictions, and obtaining variance estimates.\n",
    "\n",
    "---\n",
    "\n",
    "### `OLS.fit(X, y, use_gradient_descent=False, max_iter=1000, alpha=0.01, tol=1e-6)`\n",
    "Fits the Ordinary Least Squares (OLS) model to the dataset.\n",
    "\n",
    "#### Parameters:\n",
    "- **X** (`numpy.ndarray` or `pandas.DataFrame`): Feature matrix of shape `(n_samples, n_features)`.\n",
    "- **y** (`numpy.ndarray` or `pandas.Series`): Response vector of length `n_samples`.\n",
    "- **use_gradient_descent** (`bool`, optional): Whether to use gradient descent for optimization (default: False).\n",
    "- **max_iter** (`int`, optional): Maximum iterations for gradient descent (default: 1000).\n",
    "- **alpha** (`float`, optional): Learning rate for gradient descent (default: 0.01).\n",
    "- **tol** (`float`, optional): Convergence tolerance for gradient descent (default: 1e-6).\n",
    "\n",
    "#### Returns:\n",
    "None. Fits the model and stores coefficients in `self.beta`.\n",
    "\n",
    "---\n",
    "\n",
    "### `OLS.predict(X)`\n",
    "Predicts response values using the fitted OLS model.\n",
    "\n",
    "#### Parameters:\n",
    "- **X** (`numpy.ndarray` or `pandas.DataFrame`): Feature matrix of shape `(n_samples, n_features)`.\n",
    "\n",
    "#### Returns:\n",
    "- **predictions** (`numpy.ndarray`): Predicted values for each sample.\n",
    "\n",
    "---\n",
    "\n",
    "### `OLS.estimate_variance(X, y)`\n",
    "Estimates the variance-covariance matrix of the coefficients.\n",
    "\n",
    "#### Parameters:\n",
    "- **X** (`numpy.ndarray` or `pandas.DataFrame`): Feature matrix of shape `(n_samples, n_features)`.\n",
    "- **y** (`numpy.ndarray` or `pandas.Series`): Response vector of length `n_samples`.\n",
    "\n",
    "#### Returns:\n",
    "- **variance_matrix** (`numpy.ndarray`): Variance-covariance matrix of the coefficients.\n",
    "\n",
    "---\n",
    "\n",
    "### `GLS.fit(X, y, sigma)`\n",
    "Fits the Generalized Least Squares (GLS) model to the dataset.\n",
    "\n",
    "#### Parameters:\n",
    "- **X** (`numpy.ndarray` or `pandas.DataFrame`): Feature matrix of shape `(n_samples, n_features)`.\n",
    "- **y** (`numpy.ndarray` or `pandas.Series`): Response vector of length `n_samples`.\n",
    "- **sigma** (`numpy.ndarray`): Covariance matrix of the errors.\n",
    "\n",
    "#### Returns:\n",
    "None. Fits the model and stores coefficients in `self.beta`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Ridge.fit(X, y)`\n",
    "Fits the Ridge regression model to the dataset.\n",
    "\n",
    "#### Parameters:\n",
    "- **X** (`numpy.ndarray` or `pandas.DataFrame`): Feature matrix of shape `(n_samples, n_features)`.\n",
    "- **y** (`numpy.ndarray` or `pandas.Series`): Response vector of length `n_samples`.\n",
    "\n",
    "#### Returns:\n",
    "None. Fits the model and stores coefficients in `self.beta`.\n",
    "\n",
    "---\n",
    "\n",
    "### `Ridge.estimate_variance(X, y)`\n",
    "Estimates the variance-covariance matrix of the coefficients.\n",
    "\n",
    "#### Parameters:\n",
    "- **X** (`numpy.ndarray` or `pandas.DataFrame`): Feature matrix of shape `(n_samples, n_features)`.\n",
    "- **y** (`numpy.ndarray` or `pandas.Series`): Response vector of length `n_samples`.\n",
    "\n",
    "#### Returns:\n",
    "- **variance_matrix** (`numpy.ndarray`): Variance-covariance matrix of the coefficients.\n",
    "\n",
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Below is an example demonstrating the use of `OLS`, `GLS`, and `Ridge` regression models using synthetic datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelmontemurri/Downloads/Classes/MATH 533 - Regression and ANOVA/regression_module/venv/lib/python3.12/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/michaelmontemurri/Downloads/Classes/MATH 533 - Regression and ANOVA/regression_module\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "from stats_module.models import *\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "n_samples, n_features = 100, 5\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_beta = np.random.randn(n_features)\n",
    "y = X @ true_beta + np.random.normal(0, 0.5, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Coefficients: [-0.04722303  0.91280318  1.88309814 -1.35978426  0.5945449  -0.53310417]\n",
      "OLS Variance Matrix:\n",
      " [[ 2.56521028e-01  3.83891918e-02 -1.70855572e-02  2.33032373e-02\n",
      "   2.53067798e-02]\n",
      " [ 3.83891918e-02  2.11354611e-01 -2.56234838e-02 -6.56783237e-03\n",
      "  -5.44148650e-03]\n",
      " [-1.70855572e-02 -2.56234838e-02  2.05558025e-01  5.90663881e-04\n",
      "  -9.11745231e-03]\n",
      " [ 2.33032373e-02 -6.56783237e-03  5.90663881e-04  2.12604044e-01\n",
      "   2.20167249e-05]\n",
      " [ 2.53067798e-02 -5.44148650e-03 -9.11745231e-03  2.20167249e-05\n",
      "   1.74128093e-01]]\n",
      "OLS Summary:\n",
      " {'coefficients': array([-0.04722303,  0.91280318,  1.88309814, -1.35978426,  0.5945449 ,\n",
      "       -0.53310417]), 'r_squared': np.float64(0.966360359561293)}\n"
     ]
    }
   ],
   "source": [
    "# OLS Example\n",
    "ols_model = OLS(include_intercept=True)\n",
    "ols_model.fit(X, y)\n",
    "ols_predictions = ols_model.predict(X)\n",
    "ols_variance = ols_model.estimate_variance(X, y)\n",
    "print(\"OLS Coefficients:\", ols_model.beta)\n",
    "print(\"OLS Variance Matrix:\\n\", ols_variance)\n",
    "\n",
    "#get summary\n",
    "ols_summary = summary(ols_model, X, y)\n",
    "print(\"OLS Summary:\\n\", ols_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged after 50 iterations\n",
      "GD Coefficients: [-0.04689984  0.91160579  1.88231535 -1.35919347  0.59415345 -0.53332083]\n",
      "GD Summary:\n",
      " {'coefficients': array([-0.04689984,  0.91160579,  1.88231535, -1.35919347,  0.59415345,\n",
      "       -0.53332083]), 'r_squared': np.float64(0.9663600385784428)}\n"
     ]
    }
   ],
   "source": [
    "# Now using the gradient descent method\n",
    "gd_model = OLS(include_intercept=True)\n",
    "gd_model.fit(X, y, use_gradient_descent=True, max_iter=1000, alpha=0.1, tol=1e-6)\n",
    "gd_predictions = gd_model.predict(X)\n",
    "gd_variance = gd_model.estimate_variance(X, y)\n",
    "print(\"GD Coefficients:\", gd_model.beta)\n",
    "\n",
    "gd_summary = summary(gd_model, X, y)\n",
    "print(\"GD Summary:\\n\", gd_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLS Coefficients: [-0.07718822  0.90604494  1.8879837  -1.35086407  0.59440973 -0.51890699]\n",
      "GLS Summary:\n",
      " {'coefficients': array([-0.07718822,  0.90604494,  1.8879837 , -1.35086407,  0.59440973,\n",
      "       -0.51890699]), 'r_squared': np.float64(0.9661133093962327)}\n"
     ]
    }
   ],
   "source": [
    "# GLS Example\n",
    "sigma = np.diag(np.random.uniform(0.5, 1.5, size=n_samples))\n",
    "gls_model = GLS(include_intercept=True)\n",
    "gls_model.fit(X, y, sigma)\n",
    "gls_predictions = gls_model.predict(X)\n",
    "print(\"GLS Coefficients:\", gls_model.beta)\n",
    "\n",
    "gls_summary = summary(gls_model, X, y)\n",
    "print(\"GLS Summary:\\n\", gls_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLS Coefficients: [-0.04722303  0.91280318  1.88309814 -1.35978426  0.5945449  -0.53310417]\n",
      "OLS Coefficients: [-0.04722303  0.91280318  1.88309814 -1.35978426  0.5945449  -0.53310417]\n"
     ]
    }
   ],
   "source": [
    "# We can see that this reduces to OLS when sigma is the identity matrix\n",
    "gls_model = GLS(include_intercept=True)\n",
    "gls_model.fit(X, y, np.eye(n_samples))\n",
    "gls_predictions = gls_model.predict(X)\n",
    "gls_variance = gls_model.estimate_variance(X, y)\n",
    "print(\"GLS Coefficients:\", gls_model.beta)\n",
    "print(\"OLS Coefficients:\", ols_model.beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Variance estimator assumes homoskedasticity.\n",
      "Ridge Coefficients: [-0.04342327  0.89623975  1.85912983 -1.34226342  0.58723277 -0.52952223]\n",
      "Ridge Variance Matrix:\n",
      " [[ 2.50812226e-01  3.67571136e-02 -1.62575127e-02  2.23438619e-02\n",
      "   2.43379561e-02]\n",
      " [ 3.67571136e-02  2.07622273e-01 -2.46116995e-02 -6.40530344e-03\n",
      "  -5.37450180e-03]\n",
      " [-1.62575127e-02 -2.46116995e-02  2.02155997e-01  5.90937969e-04\n",
      "  -8.78351079e-03]\n",
      " [ 2.23438619e-02 -6.40530344e-03  5.90937969e-04  2.08982812e-01\n",
      "  -3.97043760e-05]\n",
      " [ 2.43379561e-02 -5.37450180e-03 -8.78351079e-03 -3.97043760e-05\n",
      "   1.71806002e-01]]\n",
      "Ridge Summary:\n",
      " {'coefficients': array([-0.04342327,  0.89623975,  1.85912983, -1.34226342,  0.58723277,\n",
      "       -0.52952223]), 'r_squared': np.float64(0.9661983879234871)}\n"
     ]
    }
   ],
   "source": [
    "# Ridge Example\n",
    "ridge_model = Ridge(alpha=1.0, include_intercept=True)\n",
    "ridge_model.fit(X, y)\n",
    "ridge_variance = ridge_model.estimate_variance(X, y)\n",
    "print(\"Ridge Coefficients:\", ridge_model.beta)\n",
    "print(\"Ridge Variance Matrix:\\n\", ridge_variance)\n",
    "\n",
    "ridge_summary = summary(ridge_model, X, y)\n",
    "print(\"Ridge Summary:\\n\", ridge_summary)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Matrix is ill-conditioned. Consider using regularization.\n",
      "OLS Variance Diagonal:\n",
      " [ 1.20834216e+18  2.04717669e+18  2.95280200e+18 -4.08602343e+18\n",
      " -1.12891927e+18  2.95315824e+18 -4.51184942e+17 -9.46710441e+17\n",
      " -3.40234448e+18 -1.81641217e+18 -5.09228360e+18  7.89927873e+17\n",
      "  4.37104358e+18  8.75074285e+17  3.48451179e+18  7.26130854e+18\n",
      " -2.99334628e+18 -2.96987808e+18  5.40259765e+18  2.62568932e+18\n",
      "  2.39206883e+18  6.71112101e+17  7.32080565e+18  1.47293260e+19\n",
      "  6.23603708e+18  9.17333989e+18 -1.85607765e+18 -3.00453863e+17\n",
      " -3.36391200e+17 -7.09685654e+18 -1.13617535e+18  1.43262352e+19\n",
      " -5.01195161e+17  2.72436257e+18 -5.15799590e+17 -1.90049454e+18\n",
      "  6.81042997e+18  3.10140907e+18  9.14651282e+17  4.95704364e+18\n",
      " -2.14570719e+18 -1.13790555e+18  1.20277698e+18 -3.37915505e+17\n",
      " -2.11316373e+18  9.29032094e+17  4.55253840e+18 -1.27497646e+18\n",
      "  1.37278408e+18 -1.12966011e+18]\n",
      "Warning: Variance estimator assumes homoskedasticity.\n",
      "Ridge Variance Diagonal:\n",
      " [-0.01482019 -0.00811928 -0.00476724 -0.00728944 -0.00480565 -0.00383843\n",
      " -0.00669914 -0.01030419 -0.00338391 -0.00517571 -0.00774725 -0.00619256\n",
      " -0.00602018 -0.01287938 -0.00618568 -0.00768286 -0.00820004 -0.01045589\n",
      " -0.00869603 -0.00360953 -0.00251519 -0.00999567 -0.00679988 -0.00720447\n",
      " -0.00733253 -0.00585466 -0.00626962 -0.00405689 -0.00484163 -0.00954026\n",
      " -0.00375877 -0.00417519 -0.00471375 -0.00950819 -0.00768578 -0.00639688\n",
      " -0.00796632 -0.00549511 -0.00769818 -0.00738605 -0.01038915 -0.00837756\n",
      " -0.00647554 -0.00636815 -0.00764979 -0.00983887 -0.00308174 -0.00827885\n",
      " -0.00456638 -0.00841134]\n"
     ]
    }
   ],
   "source": [
    "# Now lets generate data with p > n and see how Ridge performs compared to OLS\n",
    "\n",
    "# We can see that the variance estimates of the OLS are extremely large, indicating the solution is unstable\n",
    "# Ridge on the other hand, provides a more stable solution.\n",
    "\n",
    "n_samples, n_features = 20, 50\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_beta = np.random.randn(n_features)\n",
    "y = X @ true_beta + np.random.normal(0, 0.5, n_samples)\n",
    "\n",
    "ols_model = OLS(include_intercept=True)\n",
    "ols_model.fit(X, y)\n",
    "ols_predictions = ols_model.predict(X)\n",
    "ols_variance = ols_model.estimate_variance(X, y)\n",
    "print(\"OLS Variance Diagonal:\\n\", np.diag(ols_variance))\n",
    "\n",
    "ridge_model = Ridge(alpha=1.0, include_intercept=True)\n",
    "ridge_model.fit(X, y)\n",
    "ridge_variance = ridge_model.estimate_variance(X, y)\n",
    "print(\"Ridge Variance Diagonal:\\n\", np.diag(ridge_variance))\n",
    "\n",
    "# Compare summaries\n",
    "ols_summary = summary(ols_model, X, y)\n",
    "ridge_summary = summary(ridge_model, X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLS Time: 153.27701091766357\n",
      "Converged after 341 iterations\n",
      "GD Time: 71.31898999214172\n"
     ]
    }
   ],
   "source": [
    "# Now lets compare the time taken to fit the models with a large number of features\n",
    "\n",
    "n_samples, n_features = 20000, 10000\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "true_beta = np.random.randn(n_features)\n",
    "y = X @ true_beta + np.random.normal(0, 0.5, n_samples)\n",
    "\n",
    "start = time.time()\n",
    "ols_model = OLS(include_intercept=True)\n",
    "ols_model.fit(X, y)\n",
    "ols_predictions = ols_model.predict(X)\n",
    "end = time.time()\n",
    "print(\"OLS Time:\", end - start)\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "gd_model = OLS(include_intercept=True)\n",
    "gd_model.fit(X, y, use_gradient_descent=True, max_iter=1000, alpha=0.1, tol=1e-6)\n",
    "gd_predictions = gd_model.predict(X)\n",
    "end = time.time()\n",
    "print(\"GD Time:\", end - start)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
